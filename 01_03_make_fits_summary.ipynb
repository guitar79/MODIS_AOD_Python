{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_03_make_fits_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 모듈\n",
    "\n",
    "이 프로젝트를 위해서는 아래의 모듈이 필요하다. \n",
    "\n",
    "> numpy, pandas, matplotlib, astropy, version_information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈 설치\n",
    "\n",
    "1. 콘솔 창에서 모듈을 설치할 때는 아래와 같은 형식으로 입력하면 된다.\n",
    "\n",
    ">pip install module_name==version\n",
    "\n",
    ">conda install module_name==version\n",
    "\n",
    "2. 주피터 노트북(코랩 포함)에 설치 할 때는 아래의 셀을 실행해서 실행되지 않은 모듈을 설치할 수 있다. (pip 기준) 만약 아나콘다 환경을 사용한다면 7행을 콘다 설치 명령어에 맞게 수정하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib==3.2 in /home/guitar79/anaconda3/envs/MODIS_AOD_Python_env/lib/python3.8/site-packages (3.2.0)\n",
      "Requirement already satisfied: numpy==1.23 in /home/guitar79/anaconda3/envs/MODIS_AOD_Python_env/lib/python3.8/site-packages (1.23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/guitar79/anaconda3/envs/MODIS_AOD_Python_env/lib/python3.8/site-packages (from matplotlib==3.2) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/guitar79/anaconda3/envs/MODIS_AOD_Python_env/lib/python3.8/site-packages (from matplotlib==3.2) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/guitar79/anaconda3/envs/MODIS_AOD_Python_env/lib/python3.8/site-packages (from matplotlib==3.2) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/guitar79/anaconda3/envs/MODIS_AOD_Python_env/lib/python3.8/site-packages (from matplotlib==3.2) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/guitar79/anaconda3/envs/MODIS_AOD_Python_env/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib==3.2) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "%pip install matplotlib==3.2 numpy==1.23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈 버전 확인\n",
    "\n",
    "아래 셀을 실행하면 이 노트북을 실행한 파이썬 및 관련 모듈의 버전을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** module numpy is installed\n",
      "**** module pandas is installed\n",
      "**** module matplotlib is installed\n",
      "**** module pyhdf is installed\n",
      "**** module netCDF4 is installed\n",
      "**** module version_information is installed\n",
      "The version_information extension is already loaded. To reload it, use:\n",
      "  %reload_ext version_information\n",
      "This notebook was generated at 2023-06-08 22:56:25 (KST = GMT+0900) \n",
      "0 Python     3.8.16 64bit [GCC 11.2.0]\n",
      "1 IPython    8.12.0\n",
      "2 OS         Linux 5.15.0 73 generic x86_64 with glibc2.17\n",
      "3 numpy      1.23.0\n",
      "4 pandas     2.0.2\n",
      "5 matplotlib 3.2.0\n",
      "6 pyhdf      0.10.5\n",
      "7 netCDF4    1.6.4\n",
      "8 basemap    1.3.7\n",
      "9 basemap-data 1.3.2\n",
      "10 basemap-data-hires 1.3.2\n",
      "11 version_information 1.0.4\n"
     ]
    }
   ],
   "source": [
    "import importlib, sys, subprocess\n",
    "packages = \"numpy, pandas, matplotlib, pyhdf, netCDF4, basemap, basemap-data, basemap-data-hires, version_information\" # required modules\n",
    "pkgs = packages.split(\", \")\n",
    "for pkg in pkgs :\n",
    "    if not importlib.util.find_spec(pkg):\n",
    "        #print(f\"**** module {pkg} is not installed\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg, '-q'])\n",
    "    else: \n",
    "        print(f\"**** module {pkg} is installed\")\n",
    "\n",
    "%load_ext version_information\n",
    "import time\n",
    "now = time.strftime(\"%Y-%m-%d %H:%M:%S (%Z = GMT%z)\")\n",
    "print(f\"This notebook was generated at {now} \")\n",
    "\n",
    "vv = %version_information {packages}\n",
    "for i, pkg in enumerate(vv.packages):\n",
    "    print(f\"{i} {pkg[0]:10s} {pkg[1]:s}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import _MODIS_AOD_utilities\n",
    "import _Python_utilities\n",
    "from datetime import datetime\n",
    "import _Python_utilities\n",
    "\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# for log file\n",
    "log_dir = \"logs/\"\n",
    "log_file = \"{}{}.log\".format(log_dir, os.path.basename(__file__)[:-3])\n",
    "err_log_file = \"{}{}_err.log\".format(log_dir, os.path.basename(__file__)[:-3])\n",
    "print (\"log_file: {}\".format(log_file))\n",
    "print (\"err_log_file: {}\".format(err_log_file))\n",
    "if not os.path.exists('{0}'.format(log_dir)):\n",
    "    os.makedirs('{0}'.format(log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOINGDIRs:  ['/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2002', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2003', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2004', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2005', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2006', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2007', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2008', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2009', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2010', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2011', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2012', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2013', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2015', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2016', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2017', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2018', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2019', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2020', '/mnt/Rdata/MODIS/Aerosol/MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km/2021']\n",
      "len(DOINGDIRs):  19\n"
     ]
    }
   ],
   "source": [
    "BASEDIR = Path(\"/mnt/Rdata/MODIS/Aerosol\")\n",
    "DOINGDIR = BASEDIR/ \"MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 3km\"\n",
    "DOINGDIR = BASEDIR/\"MODIS Aqua C6.1 - Aerosol 5-Min L2 Swath 10km\"\n",
    "\n",
    "YEARDIRs = sorted(_Python_utilities.getFullnameListOfsubDirs(DOINGDIR))\n",
    "print (\"YEARDIRs: \", format(YEARDIRs))\n",
    "print (\"len(YEARDIRs): \", format(len(YEARDIRs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#######################################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# for log file\u001b[39;00m\n\u001b[1;32m      3\u001b[0m log_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlogs/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m log_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m.log\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(log_dir, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(\u001b[39m__file__\u001b[39;49m)[:\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m])\n\u001b[1;32m      5\u001b[0m err_log_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m_err.log\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(log_dir, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(\u001b[39m__file__\u001b[39m)[:\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mlog_file: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(log_file))\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "for YEARDIR in YEARDIRs[:1] :\n",
    "    YEARDIR = Path(YEARDIRs)\n",
    "    DAYDIRs = _Python_utilities.getFullnameListOfallFiles(str(YEARDIRs))\n",
    "    \n",
    "    for DAYDIR in DAYDIRs[:1] :\n",
    "        YEARDIR\n",
    "\n",
    "\n",
    "    ccd_fpath = Path(f\"{DOINGDIR/DOINGDIR.parts[-1]}.csv\")\n",
    "    print(\"ccd_fpath\", ccd_fpath)\n",
    "    DOINGSUBDIRs = sorted(_Python_utilities.getFullnameListOfallsubDirs(str(DOINGDIR)))\n",
    "    t = os.path.getmtime(ccd_fpath)\n",
    "    ccd_fpath_dt = datetime.fromtimestamp(t)\n",
    "    #print(\"ccd_fpath_dt: \", ccd_fpath_dt)\n",
    "    if ccd_fpath.exists() \\\n",
    "        and ccd_fpath_dt < datetime.now() + timedelta(weeks=-2) :\n",
    "        print(f\"{str(ccd_fpath)} is already exist and is not old...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = os.path.getmtime(ccd_fpath)\n",
    "# ccd_fpath_dt = datetime.fromtimestamp(t)\n",
    "# print(ccd_fpath_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccd_fpath_dt > datetime.now() + timedelta(weeks=-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccd_fpath.exists() \\\n",
    "        #and ccd_fpath_dt < datetime.now() + timedelta(weeks=-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DOINGDIR in DOINGDIRs[:1] :\n",
    "    DOINGDIR = Path(DOINGDIR)\n",
    "    ccd_fpath = Path(f\"{DOINGDIR/DOINGDIR.parts[-1]}.csv\")\n",
    "    print(\"ccd_fpath\", ccd_fpath)\n",
    "    DOINGSUBDIRs = sorted(_Python_utilities.getFullnameListOfallsubDirs(str(DOINGDIR)))\n",
    "    t = os.path.getmtime(ccd_fpath)\n",
    "    ccd_fpath_dt = datetime.fromtimestamp(t)\n",
    "    #print(\"ccd_fpath_dt: \", ccd_fpath_dt)\n",
    "    if ccd_fpath.exists() \\\n",
    "        and ccd_fpath_dt < datetime.now() + timedelta(weeks=-2) :\n",
    "        print(f\"{str(ccd_fpath)} is already exist and is not old...\")\n",
    "            \n",
    "    else : \n",
    "        summary_all = pd.DataFrame()\n",
    "\n",
    "        for DOINGSUBDIR in DOINGSUBDIRs[:1] :\n",
    "            DOINGSUBDIR = Path(DOINGSUBDIR)\n",
    "            print(\"DOINGSUBDIR\", DOINGSUBDIR)\n",
    "            fits_in_dir = sorted(list(DOINGSUBDIR.glob('*.fit*')))\n",
    "            print(\"fits_in_dir\", fits_in_dir)\n",
    "            print(\"len(fits_in_dir)\", len(fits_in_dir))\n",
    "            if len(fits_in_dir) == 0 :\n",
    "                print(f\"There is no fits fils in {DOINGSUBDIR}\")\n",
    "                pass\n",
    "            else : \n",
    "                save_fpath2 = DOINGSUBDIR / f\"{DOINGSUBDIR.parts[-1]}.csv\"\n",
    "                save_fpath = DOINGSUBDIR / f\"summary_{DOINGSUBDIR.parts[-1]}.csv\"\n",
    "                print (f\"Starting...\\n{DOINGSUBDIR.name}\")\n",
    "                if save_fpath2.exists():\n",
    "                    os.remove(str(save_fpath2))\n",
    "                    print (f\"{str(save_fpath2)} is deleted...\")\n",
    "                \n",
    "                t = os.path.getmtime(save_fpath)\n",
    "                save_fpath_dt = datetime.fromtimestamp(t)\n",
    "                #print(\"save_fpath_dt: \", save_fpath_dt)\n",
    "                if save_fpath.exists() \\\n",
    "                    and save_fpath_dt < datetime.now() + timedelta(weeks=-2) :\n",
    "                    print(f\"{str(save_fpath)} is already exist and is not old...\")\n",
    "                    summary = pd.read_csv(str(save_fpath))\n",
    "                \n",
    "                else : \n",
    "                    summary = yfu.make_summary(DOINGSUBDIR/\"*.fit*\",\n",
    "                                output = save_fpath,\n",
    "                                verbose = False\n",
    "                                )\n",
    "                    print(f\"{save_fpath} is created...\")\n",
    "                summary_all = pd.concat([summary_all, summary], axis = 0)\n",
    "        \n",
    "        summary_all.reset_index(inplace=True)\n",
    "        summary_all.to_csv(str(ccd_fpath))\n",
    "        print(f\"{ccd_fpath} is created...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "for DOINGDIR in DOINGDIRs[:2] :\n",
    "    DOINGDIR = Path(DOINGDIR)\n",
    "    DOINGSUBDIRs = sorted(_Python_utilities.getFullnameListOfallsubDirs(str(DOINGDIR)))\n",
    "    ccd_fpath = Path(f\"{DOINGDIR/DOINGDIR.parts[-1]}.csv\")\n",
    "    print(\"ccd_fpath\", ccd_fpath)\n",
    "\n",
    "    if ccd_fpath.exists() or False:\n",
    "        print(f\"{str(ccd_fpath)} is already exist...\")\n",
    "\n",
    "    else : \n",
    "        summary_all = pd.DataFrame()\n",
    "\n",
    "        for DOINGSUBDIR in DOINGSUBDIRs[:10] :\n",
    "            DOINGSUBDIR = Path(DOINGSUBDIR)\n",
    "            print(\"DOINGSUBDIR\", DOINGSUBDIR)\n",
    "            fits_in_dir = sorted(list(DOINGSUBDIR.glob('*.fit*')))\n",
    "            print(\"fits_in_dir\", fits_in_dir)\n",
    "            print(\"len(fits_in_dir)\", len(fits_in_dir))\n",
    "            if len(fits_in_dir) == 0 :\n",
    "                print(f\"There is no fits fils in {DOINGSUBDIR}\")\n",
    "                pass\n",
    "            else : \n",
    "                save_fpath2 = DOINGSUBDIR / f\"{DOINGSUBDIR.parts[-1]}.csv\"\n",
    "                save_fpath = DOINGSUBDIR / f\"summary_{DOINGSUBDIR.parts[-1]}.csv\"\n",
    "                print (f\"Starting...\\n{DOINGSUBDIR.name}\")\n",
    "                if save_fpath2.exists():\n",
    "                    os.remove(str(save_fpath2))\n",
    "                    print (f\"{str(save_fpath2)} is deleted...\")\n",
    "                \n",
    "                if save_fpath.exists():\n",
    "                    print(f\"{str(save_fpath)} is already exist...\")\n",
    "                    summary = pd.read_csv(str(save_fpath))\n",
    "                \n",
    "                else : \n",
    "                    summary = yfu.make_summary(DOINGSUBDIR/\"*.fit*\",\n",
    "                                output = save_fpath,\n",
    "                                verbose = False\n",
    "                                )\n",
    "                    print(f\"{save_fpath} is created...\")\n",
    "                summary_all = pd.concat([summary_all, summary], axis = 0)\n",
    "        \n",
    "        summary_all.reset_index(inplace=True)\n",
    "        summary_all.to_csv(str(ccd_fpath))\n",
    "        print(f\"{ccd_fpath} is created...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(fits_in_dir) == 0 :\n",
    "    print(f\"There is no fits fils in {DOINGSUBDIR}\")\n",
    "    pass\n",
    "else : \n",
    "    print(\"ccd_fpath\", ccd_fpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ccd_fpath.exists():\n",
    "    print(f\"{BASEDIR/ccd_dir}.csv is already exist...\")\n",
    "else : \n",
    "    summary_all = pd.DataFrame()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_all = pd.DataFrame()\n",
    "save_fpath2 = fpath/f\"{fpath.parts[-1]}.csv\"\n",
    "save_fpath = fpath/f\"summary_{fpath.parts[-1]}.csv\"\n",
    "print (f\"Starting...\\n{fpath.name}\")\n",
    "if save_fpath2.exists():\n",
    "    os.remove(str(save_fpath2))\n",
    "    print (f\"{str(save_fpath2)} is deleted...\")\n",
    "\n",
    "if save_fpath.exists():\n",
    "    print(f\"{str(save_fpath)} is already exist...\")\n",
    "    summary = pd.read_csv(str(save_fpath))\n",
    "\n",
    "else : \n",
    "    summary = yfu.make_summary(fpath/\"*.fit*\",\n",
    "                output = save_fpath,\n",
    "                verbose = False\n",
    "                )\n",
    "    print(f\"{save_fpath} is created...\")\n",
    "summary_all = pd.concat([summary_all, summary], axis = 0)\n",
    "summary_all.to_csv(f\"{BASEDIR/ccd_dir}.csv\")\n",
    "summary_all.reset_index(inplace=True)\n",
    "print(f\"{BASEDIR/ccd_dir}.csv is created...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro_Python_ubuntu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73147851ede918c26f741c84bca6ea3575da18885c8fa4aa4a9fbe5902a3c298"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
